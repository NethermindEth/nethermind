name: Run EXPB Reproducible Benchmarks

on:
  workflow_dispatch:
    inputs:
      last:
        description: Number of recent master commits to look back from HEAD
        required: true
        type: number
        default: 100
      step:
        description: Pick every Nth commit that has a Docker image (e.g. 10 means every 10th image within the window)
        required: true
        type: number
        default: 10
      expb_repo:
        description: execution-payloads-benchmarks repository in owner/repo format
        required: false
        default: NethermindEth/execution-payloads-benchmarks
      expb_branch:
        description: execution-payloads-benchmarks branch or tag
        required: false
        default: main
      state_layout:
        description: State layout mode
        required: true
        type: choice
        options:
          - halfpath
          - flat
        default: halfpath
      payload_set:
        description: Payload set mode
        required: true
        type: choice
        options:
          - realblocks
          - superblocks
        default: superblocks
      delay_seconds:
        description: Value used to replace <<DELAY>> placeholder (integer)
        required: false
        default: "0"
      additional_extra_flags:
        description: >-
          Optional extra Nethermind flags. Example (single): --Merge.SweepMemory=NoGC.
          Example (multiple): --Sync.FastSync=false, --Pruning.CacheMb=12000
          (or provide one flag per line).
        required: false
        default: ""

permissions:
  contents: read
  actions: read

jobs:
  resolve-images:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.resolve.outputs.matrix }}
      ordered_tags: ${{ steps.resolve.outputs.ordered_tags }}
      config_file: ${{ steps.resolve.outputs.config_file }}
      expb_repo: ${{ steps.resolve.outputs.expb_repo }}
      expb_branch: ${{ steps.resolve.outputs.expb_branch }}
      delay_seconds: ${{ steps.resolve.outputs.delay_seconds }}
      additional_extra_flags: ${{ steps.resolve.outputs.additional_extra_flags }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v6
        with:
          ref: master
          fetch-depth: ${{ inputs.last }}

      - name: Resolve Docker images from Docker Hub
        id: resolve
        shell: bash
        env:
          LAST: ${{ inputs.last }}
          STEP: ${{ inputs.step }}
          STATE_LAYOUT: ${{ inputs.state_layout }}
          PAYLOAD_SET: ${{ inputs.payload_set }}
          EXPB_REPO: ${{ inputs.expb_repo }}
          EXPB_BRANCH: ${{ inputs.expb_branch }}
          DELAY_SECONDS: ${{ inputs.delay_seconds }}
          ADDITIONAL_EXTRA_FLAGS: ${{ inputs.additional_extra_flags }}
        run: |
          set -euo pipefail

          if ! [[ "${LAST}" =~ ^[0-9]+$ ]] || [[ "${LAST}" -lt 1 ]]; then
            echo "last must be a positive integer, got '${LAST}'."
            exit 1
          fi

          if ! [[ "${STEP}" =~ ^[0-9]+$ ]] || [[ "${STEP}" -lt 1 ]]; then
            echo "step must be a positive integer, got '${STEP}'."
            exit 1
          fi

          if ! [[ "${DELAY_SECONDS}" =~ ^-?[0-9]+$ ]]; then
            echo "delay_seconds must be an integer, got '${DELAY_SECONDS}'."
            exit 1
          fi

          # Resolve config file from state_layout + payload_set
          if [[ "${STATE_LAYOUT}" == "flat" && "${PAYLOAD_SET}" == "superblocks" ]]; then
            config_file="github-action-compressed-mainnet-flat.yaml"
          elif [[ "${STATE_LAYOUT}" == "flat" && "${PAYLOAD_SET}" == "realblocks" ]]; then
            config_file="github-action-mainnet-flat.yaml"
          elif [[ "${STATE_LAYOUT}" == "halfpath" && "${PAYLOAD_SET}" == "superblocks" ]]; then
            config_file="github-action-compressed-mainnet.yaml"
          else
            config_file="github-action-mainnet.yaml"
          fi

          # Get last LAST commit sha7s from master (newest first)
          echo "Getting last ${LAST} master commits..."
          mapfile -t commit_shas < <(git log --format='%h' -n "${LAST}" HEAD)
          echo "Got ${#commit_shas[@]} commits from master."

          # Fetch all master-* tags from Docker Hub into a set for fast lookup
          echo "Fetching master-* tags from Docker Hub..."
          declare -A available_tags
          page=1
          page_size=100
          fetched=0

          while true; do
            url="https://hub.docker.com/v2/repositories/nethermindeth/nethermind/tags?page_size=${page_size}&page=${page}&name=master-&ordering=-last_updated"
            response=$(curl -sf "${url}" || echo '{"results":[]}')

            mapfile -t page_tags < <(echo "${response}" | jq -r '.results[].name // empty')

            if [[ "${#page_tags[@]}" -eq 0 ]]; then
              break
            fi

            for t in "${page_tags[@]}"; do
              if [[ "${t}" =~ ^master-[0-9a-f]{7}$ ]]; then
                available_tags["${t}"]=1
                fetched=$(( fetched + 1 ))
              fi
            done

            # Stop fetching once we have more tags than commits (no point going further)
            if [[ "${fetched}" -ge "${LAST}" ]]; then
              break
            fi

            # Check if there are more pages
            has_next=$(echo "${response}" | jq -r '.next // empty')
            if [[ -z "${has_next}" ]]; then
              break
            fi

            page=$(( page + 1 ))
          done

          echo "Fetched ${fetched} master-* tags from Docker Hub."

          # Walk commits newest-first, collect those with Docker images
          images_in_window=()
          for sha7 in "${commit_shas[@]}"; do
            tag="master-${sha7}"
            if [[ -n "${available_tags[${tag}]+x}" ]]; then
              images_in_window+=("${tag}")
            fi
          done

          echo "Found ${#images_in_window[@]} Docker images within the last ${LAST} commits."

          if [[ "${#images_in_window[@]}" -eq 0 ]]; then
            echo "No Docker images found within the last ${LAST} master commits."
            exit 1
          fi

          # Apply step: pick every Nth image (newest first)
          selected_tags=()
          for (( i=0; i<${#images_in_window[@]}; i+=STEP )); do
            selected_tags+=("${images_in_window[$i]}")
          done

          echo "Selected ${#selected_tags[@]} images after applying step=${STEP}."

          # GitHub Actions matrix has a limit of 256 entries
          if [[ "${#selected_tags[@]}" -gt 256 ]]; then
            echo "Warning: truncating to 256 matrix entries (GitHub Actions limit)."
            selected_tags=("${selected_tags[@]:0:256}")
          fi

          # Resolve dates and print selected tags
          declare -a selected_dates
          for t in "${selected_tags[@]}"; do
            sha="${t#master-}"
            commit_date=$(git log --format='%cs' -n 1 "${sha}" 2>/dev/null || echo "unknown")
            msg=$(git log --format='%s' -n 1 "${sha}" 2>/dev/null | head -c 80 || echo "")
            selected_dates+=("${commit_date}")
            echo "  ${t} ${commit_date} (${msg})"
          done

          # Build matrix JSON and ordered list
          # selected_tags is newest-first; matrix runs in that order, summary reverses
          matrix_json='{"include":['
          ordered_json='['
          for i in "${!selected_tags[@]}"; do
            tag="${selected_tags[$i]}"
            sha="${tag#master-}"
            date="${selected_dates[$i]}"
            if [[ "${i}" -gt 0 ]]; then
              matrix_json+=','
              ordered_json+=','
            fi
            matrix_json+="{\"tag\":\"${tag}\",\"sha\":\"${sha}\",\"date\":\"${date}\"}"
            ordered_json+="{\"tag\":\"${tag}\",\"sha\":\"${sha}\",\"date\":\"${date}\"}"
          done
          matrix_json+=']}'
          ordered_json+=']'

          {
            echo "matrix=${matrix_json}"
            echo "ordered_tags=${ordered_json}"
            echo "config_file=${config_file}"
            echo "expb_repo=${EXPB_REPO}"
            echo "expb_branch=${EXPB_BRANCH}"
            echo "delay_seconds=${DELAY_SECONDS}"
            echo "additional_extra_flags<<EOF"
            printf '%s\n' "${ADDITIONAL_EXTRA_FLAGS}"
            echo "EOF"
          } >> "${GITHUB_OUTPUT}"

  benchmark:
    name: benchmark (${{ matrix.tag }} / ${{ matrix.date }})
    needs: [resolve-images]
    strategy:
      matrix: ${{ fromJson(needs.resolve-images.outputs.matrix) }}
      max-parallel: 1
      fail-fast: false
    runs-on: [self-hosted, reproducible-benchmarks]
    timeout-minutes: 720
    env:
      EXPB_DATA_DIR: /mnt/sda/expb-data
      CONFIG_FILE: ${{ needs.resolve-images.outputs.config_file }}
      NETHERMIND_IMAGE: nethermindeth/nethermind:${{ matrix.tag }}
      CLEANUP_GRACE_SECONDS: "90"
    steps:
      - name: Print resolved inputs
        run: |
          echo "Retrospective benchmark run"
          echo "Docker image: ${NETHERMIND_IMAGE}"
          echo "Image tag: ${{ matrix.tag }}"
          echo "Commit: ${{ matrix.sha }}"
          echo "Config file: ${EXPB_DATA_DIR}/${CONFIG_FILE}"
          echo "Delay placeholder value: ${{ needs.resolve-images.outputs.delay_seconds }}"
          echo "Cleanup grace period (s): ${CLEANUP_GRACE_SECONDS}"

      - name: Ensure EXPB config file exists
        shell: bash
        run: |
          set -euo pipefail
          if [[ ! -f "${EXPB_DATA_DIR}/${CONFIG_FILE}" ]]; then
            echo "Config file '${EXPB_DATA_DIR}/${CONFIG_FILE}' does not exist."
            echo "Available github-action config files in '${EXPB_DATA_DIR}':"
            ls -1 "${EXPB_DATA_DIR}"/github-action*mainnet*.yaml || true
            exit 1
          fi

      - name: Render benchmark config
        id: render-config
        shell: bash
        env:
          SOURCE_CONFIG_FILE: ${{ env.EXPB_DATA_DIR }}/${{ env.CONFIG_FILE }}
          RENDERED_CONFIG_FILE: ${{ runner.temp }}/rendered-expb-config-${{ matrix.tag }}.yaml
          DOCKER_TAG: ${{ matrix.tag }}
          DELAY_SECONDS: ${{ needs.resolve-images.outputs.delay_seconds }}
          SCENARIO_NAME: nethermind-retrospective-${{ matrix.tag }}
          ADDITIONAL_EXTRA_FLAGS: ${{ needs.resolve-images.outputs.additional_extra_flags }}
        run: |
          set -euo pipefail
          flags_file="$(mktemp)"
          printf '%s' "${ADDITIONAL_EXTRA_FLAGS}" \
            | tr '\r' '\n' \
            | tr ',' '\n' \
            | sed 's/^[[:space:]]*//; s/[[:space:]]*$//' \
            | sed '/^$/d' \
            | awk '
                function emit_pending() {
                  if (pending != "") {
                    print pending
                    pending = ""
                  }
                }
                {
                  line = $0

                  # Convert "--Key Value" to "--Key=Value" to avoid bare value tokens.
                  if (match(line, /^--[^[:space:]=]+[[:space:]]+/)) {
                    key = substr(line, 1, RLENGTH)
                    sub(/[[:space:]]+$/, "", key)
                    value = substr(line, RLENGTH + 1)
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "", value)
                    emit_pending()
                    print key "=" value
                    next
                  }

                  if (line ~ /^--/) {
                    emit_pending()
                    pending = line
                    next
                  }

                  if (pending != "") {
                    print pending "=" line
                    pending = ""
                  } else {
                    print line
                  }
                }
                END {
                  emit_pending()
                }
              ' \
            > "${flags_file}"

          sed \
            -e "s#<<DOCKER_TAG>>#${DOCKER_TAG}#g" \
            -e "s#<<DELAY>>#${DELAY_SECONDS}#g" \
            -e "s#^\([[:space:]]*\)nethermind:#\1${SCENARIO_NAME}:#g" \
            "${SOURCE_CONFIG_FILE}" \
            | awk -v flags_file="${flags_file}" '
                BEGIN {
                  while ((getline flag < flags_file) > 0) {
                    flags[++flags_count] = flag
                  }
                  close(flags_file)
                }
                {
                  print
                  if (flags_count > 0 && $0 ~ /^[[:space:]]*extra_flags:[[:space:]]*$/) {
                    match($0, /^[[:space:]]*/)
                    indent = substr($0, RSTART, RLENGTH)
                    for (i = 1; i <= flags_count; i++) {
                      print indent "  - " flags[i]
                    }
                  }
                }
              ' > "${RENDERED_CONFIG_FILE}"

          echo "rendered_config_file=${RENDERED_CONFIG_FILE}" >> "${GITHUB_OUTPUT}"

      - name: Install or upgrade expb
        shell: bash
        env:
          EXPB_REPO: ${{ needs.resolve-images.outputs.expb_repo }}
          EXPB_BRANCH: ${{ needs.resolve-images.outputs.expb_branch }}
        run: |
          set -euo pipefail

          if ! command -v uv >/dev/null 2>&1; then
            echo "uv is required on runner but was not found in PATH."
            exit 1
          fi

          if [[ "${EXPB_REPO}" == "NethermindEth/execution-payloads-benchmarks" && "${EXPB_BRANCH}" == "main" ]]; then
            expb_source="git+https://github.com/NethermindEth/execution-payloads-benchmarks"
          elif [[ -n "${EXPB_BRANCH}" ]]; then
            expb_source="git+https://github.com/${EXPB_REPO}@${EXPB_BRANCH}"
          else
            expb_source="git+https://github.com/${EXPB_REPO}"
          fi

          echo "Installing expb from ${expb_source}"
          uv tool install --force --from "${expb_source}" expb
          echo "$(uv tool dir --bin)" >> "${GITHUB_PATH}"

      - name: Run expb scenarios
        id: run-expb
        continue-on-error: true
        shell: bash
        working-directory: ${{ env.EXPB_DATA_DIR }}
        env:
          RAW_RUN_LOG: ${{ runner.temp }}/expb-run-${{ matrix.tag }}.log
        run: |
          set -euo pipefail
          expb_pid=""
          : > "${RAW_RUN_LOG}"

          on_terminate() {
            echo "Termination signal received. Waiting up to ${CLEANUP_GRACE_SECONDS}s for expb cleanup."
            if [[ -n "${expb_pid}" ]] && kill -0 "${expb_pid}" 2>/dev/null; then
              kill -TERM "${expb_pid}" 2>/dev/null || true

              remaining="${CLEANUP_GRACE_SECONDS}"
              while [[ "${remaining}" -gt 0 ]]; do
                if ! kill -0 "${expb_pid}" 2>/dev/null; then
                  echo "expb exited during cleanup grace period."
                  break
                fi
                sleep 1
                remaining=$((remaining - 1))
              done

              if kill -0 "${expb_pid}" 2>/dev/null; then
                echo "Cleanup grace period elapsed. Forcing expb shutdown."
                kill -KILL "${expb_pid}" 2>/dev/null || true
              fi
            fi

            if [[ -f "${RAW_RUN_LOG}" ]]; then
              cat "${RAW_RUN_LOG}"
            fi
            exit 143
          }

          trap on_terminate TERM INT

          expb execute-scenarios \
            --config-file "${{ steps.render-config.outputs.rendered_config_file }}" \
            --per-payload-metrics \
            --per-payload-metrics-logs \
            --print-logs \
            > "${RAW_RUN_LOG}" 2>&1 &
          expb_pid=$!

          set +e
          wait "${expb_pid}"
          expb_exit_code=$?
          set -e

          cat "${RAW_RUN_LOG}"
          exit "${expb_exit_code}"

      - name: Analyze benchmark output
        id: analyze
        if: always()
        shell: bash
        env:
          RAW_RUN_LOG: ${{ runner.temp }}/expb-run-${{ matrix.tag }}.log
          TAG: ${{ matrix.tag }}
          SHA: ${{ matrix.sha }}
        run: |
          set -euo pipefail

          clean_log="${RUNNER_TEMP}/expb-run-${TAG}.clean.log"
          exception_lines="${RUNNER_TEMP}/expb-exceptions-${TAG}.log"
          invalid_block_lines="${RUNNER_TEMP}/expb-invalid-blocks-${TAG}.log"
          processing_ms="${RUNNER_TEMP}/expb-processing-ms-${TAG}.txt"
          processing_ms_sorted="${RUNNER_TEMP}/expb-processing-ms-sorted-${TAG}.txt"
          metrics_dir="${RUNNER_TEMP}/expb-metrics-${TAG}"

          mkdir -p "${metrics_dir}"

          if [[ ! -f "${RAW_RUN_LOG}" ]]; then
            echo "Run output log '${RAW_RUN_LOG}' was not produced."
            {
              echo "TAG=${TAG}"
              echo "SHA=${SHA}"
              echo "ERROR=no_log"
            } > "${metrics_dir}/metrics.env"
            exit 1
          fi

          sed -E 's/\x1B\[[0-9;?]*[ -/]*[@-~]//g' "${RAW_RUN_LOG}" > "${clean_log}"

          grep -in "Exception" "${clean_log}" > "${exception_lines}" || true
          exception_found="false"
          if [[ -s "${exception_lines}" ]]; then
            exception_found="true"
            echo "Found Exception lines in benchmark output:"
            head -n 40 "${exception_lines}"
          fi

          grep -Ein "invalid[[:space:]_-]*block" "${clean_log}" > "${invalid_block_lines}" || true
          invalid_block_found="false"
          if [[ -s "${invalid_block_lines}" ]]; then
            invalid_block_found="true"
            echo "Found invalid block lines in benchmark output:"
            head -n 40 "${invalid_block_lines}"
          fi

          awk -F'|' '
            /^[[:space:]]*\|[[:space:]]*[0-9]+[[:space:]]*\|[[:space:]]*[0-9]+[[:space:]]*\|[[:space:]]*[0-9]+(\.[0-9]+)?[[:space:]]*\|[[:space:]]*$/ {
              value = $4
              gsub(/^[[:space:]]+|[[:space:]]+$/, "", value)
              if (value ~ /^[0-9]+(\.[0-9]+)?$/) {
                print value
              }
            }
          ' "${clean_log}" > "${processing_ms}"

          count=$(wc -l < "${processing_ms}")
          count="${count//[[:space:]]/}"

          if [[ "${count}" -eq 0 ]]; then
            echo "Could not extract per-payload processing_ms rows from benchmark output."
            {
              echo "TAG=${TAG}"
              echo "SHA=${SHA}"
              echo "EXCEPTION_FOUND=${exception_found}"
              echo "INVALID_BLOCK_FOUND=${invalid_block_found}"
              echo "ERROR=no_metrics"
            } > "${metrics_dir}/metrics.env"
            exit 1
          fi

          sort -n "${processing_ms}" > "${processing_ms_sorted}"

          min=$(head -n 1 "${processing_ms_sorted}")
          max=$(tail -n 1 "${processing_ms_sorted}")
          avg=$(awk '{sum += $1} END {printf "%.2f", sum / NR}' "${processing_ms_sorted}")
          if (( count % 2 == 1 )); then
            median_index=$(( (count + 1) / 2 ))
            median=$(sed -n "${median_index}p" "${processing_ms_sorted}")
          else
            lower_index=$(( count / 2 ))
            upper_index=$(( lower_index + 1 ))
            lower_value=$(sed -n "${lower_index}p" "${processing_ms_sorted}")
            upper_value=$(sed -n "${upper_index}p" "${processing_ms_sorted}")
            median=$(awk -v a="${lower_value}" -v b="${upper_value}" 'BEGIN {printf "%.2f", (a + b) / 2}')
          fi

          p90_index=$(( (90 * count + 99) / 100 ))
          p95_index=$(( (95 * count + 99) / 100 ))
          p99_index=$(( (99 * count + 99) / 100 ))

          p90=$(sed -n "${p90_index}p" "${processing_ms_sorted}")
          p95=$(sed -n "${p95_index}p" "${processing_ms_sorted}")
          p99=$(sed -n "${p99_index}p" "${processing_ms_sorted}")

          {
            echo "TAG=${TAG}"
            echo "SHA=${SHA}"
            echo "EXCEPTION_FOUND=${exception_found}"
            echo "INVALID_BLOCK_FOUND=${invalid_block_found}"
            echo "COUNT=${count}"
            echo "AVG=${avg}"
            echo "MEDIAN=${median}"
            echo "P90=${p90}"
            echo "P95=${p95}"
            echo "P99=${p99}"
            echo "MIN=${min}"
            echo "MAX=${max}"
          } > "${metrics_dir}/metrics.env"

          echo "Metrics for ${TAG}:"
          cat "${metrics_dir}/metrics.env"

      - name: Upload metrics artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: expb-metrics-${{ matrix.tag }}
          path: ${{ runner.temp }}/expb-metrics-${{ matrix.tag }}/metrics.env
          retention-days: 30

      - name: Enforce run quality gates
        if: always()
        shell: bash
        run: |
          set -euo pipefail

          if [[ "${{ steps.run-expb.outcome }}" != "success" ]]; then
            echo "expb execute-scenarios did not finish successfully for ${{ matrix.tag }}."
            echo "Continuing retrospective run (fail-fast is disabled)."
          fi

          if [[ "${{ steps.analyze.outputs.exception_found }}" == "true" ]]; then
            echo "Exceptions were detected for ${{ matrix.tag }}."
          fi

          if [[ "${{ steps.analyze.outputs.invalid_block_found }}" == "true" ]]; then
            echo "Invalid block lines were detected for ${{ matrix.tag }}."
          fi

      - name: Cleanup rendered config
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          rm -f "${{ runner.temp }}/rendered-expb-config-${{ matrix.tag }}.yaml" || true
          rendered_config_file="${{ steps.render-config.outputs.rendered_config_file }}"
          if [[ -n "${rendered_config_file}" ]]; then
            rm -f "${rendered_config_file}" || true
          fi

  summary:
    needs: [resolve-images, benchmark]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Download all metrics artifacts
        uses: actions/download-artifact@v4
        with:
          path: ${{ runner.temp }}/all-metrics
          pattern: expb-metrics-*

      - name: Build comparison table
        shell: bash
        env:
          METRICS_DIR: ${{ runner.temp }}/all-metrics
          ORDERED_TAGS: ${{ needs.resolve-images.outputs.ordered_tags }}
        run: |
          set -euo pipefail

          summary_file="${RUNNER_TEMP}/retrospective-summary.md"

          # Parse ordered tags JSON â€” newest first from resolve, reverse to oldest-first
          mapfile -t tags < <(echo "${ORDERED_TAGS}" | jq -r '.[].tag' | tac)
          mapfile -t shas < <(echo "${ORDERED_TAGS}" | jq -r '.[].sha' | tac)
          mapfile -t dates < <(echo "${ORDERED_TAGS}" | jq -r '.[].date' | tac)

          load_metric() {
            local file="$1"
            local key="$2"
            if [[ -f "${file}" ]]; then
              grep -E "^${key}=" "${file}" | head -n 1 | cut -d'=' -f2- || true
            fi
          }

          percentage_delta() {
            local current="$1"
            local baseline="$2"
            if [[ -z "${current}" || -z "${baseline}" ]]; then
              echo "n/a"
              return
            fi
            awk -v c="${current}" -v b="${baseline}" 'BEGIN {
              if (b == 0) { print "n/a"; }
              else { printf "%+.2f%%", ((c - b) / b) * 100; }
            }'
          }

          {
            echo "## EXPB Retrospective Benchmark Results"
            echo ""
            echo "Benchmarked ${#tags[@]} Docker images from oldest to newest (last=${{ inputs.last }}, step=${{ inputs.step }})."
            echo ""
            echo "| # | Image Tag | Date | AVG (ms) | Median (ms) | P90 (ms) | P95 (ms) | P99 (ms) | Min (ms) | Max (ms) | AVG Delta vs Oldest |"
            echo "|---|-----------|------|----------|-------------|----------|----------|----------|----------|----------|---------------------|"
          } > "${summary_file}"

          baseline_avg=""

          for i in "${!tags[@]}"; do
            tag="${tags[$i]}"
            sha="${shas[$i]}"
            date="${dates[$i]}"
            idx=$(( i + 1 ))

            metrics_file="${METRICS_DIR}/expb-metrics-${tag}/metrics.env"

            if [[ ! -f "${metrics_file}" ]]; then
              echo "| ${idx} | \`${tag}\` | ${date} | - | - | - | - | - | - | - | no data |" >> "${summary_file}"
              continue
            fi

            error=$(load_metric "${metrics_file}" "ERROR")
            if [[ -n "${error}" ]]; then
              exception=$(load_metric "${metrics_file}" "EXCEPTION_FOUND")
              invalid=$(load_metric "${metrics_file}" "INVALID_BLOCK_FOUND")
              status="${error}"
              if [[ "${exception}" == "true" ]]; then
                status="${status} :warning: exceptions"
              fi
              if [[ "${invalid}" == "true" ]]; then
                status="${status} :warning: invalid blocks"
              fi
              echo "| ${idx} | \`${tag}\` | ${date} | - | - | - | - | - | - | - | ${status} |" >> "${summary_file}"
              continue
            fi

            avg=$(load_metric "${metrics_file}" "AVG")
            median=$(load_metric "${metrics_file}" "MEDIAN")
            p90=$(load_metric "${metrics_file}" "P90")
            p95=$(load_metric "${metrics_file}" "P95")
            p99=$(load_metric "${metrics_file}" "P99")
            min_val=$(load_metric "${metrics_file}" "MIN")
            max_val=$(load_metric "${metrics_file}" "MAX")
            exception=$(load_metric "${metrics_file}" "EXCEPTION_FOUND")
            invalid=$(load_metric "${metrics_file}" "INVALID_BLOCK_FOUND")

            if [[ -z "${baseline_avg}" && -n "${avg}" ]]; then
              baseline_avg="${avg}"
            fi

            delta=$(percentage_delta "${avg}" "${baseline_avg}")

            warnings=""
            if [[ "${exception}" == "true" ]]; then
              warnings=" :warning:"
            fi
            if [[ "${invalid}" == "true" ]]; then
              warnings="${warnings} :no_entry:"
            fi

            echo "| ${idx} | \`${tag}\` | ${date} | ${avg} | ${median} | ${p90} | ${p95} | ${p99} | ${min_val} | ${max_val} | ${delta}${warnings} |" >> "${summary_file}"
          done

          {
            echo ""
            echo "**Legend:** :warning: = exceptions detected, :no_entry: = invalid blocks detected"
            echo ""
            echo "**Delta vs Oldest** shows the percentage change in AVG processing time compared to the oldest (first) image in the run."
          } >> "${summary_file}"

          echo "--- Retrospective Summary ---"
          cat "${summary_file}"

          cat "${summary_file}" >> "${GITHUB_STEP_SUMMARY}"
